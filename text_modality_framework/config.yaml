filename_pretrain: 'text_modality_framework/data/sentiment_data/huggingface_pretrain.csv'
filename_train: 'text_modality_framework/data/sentiment_data/huggingface_remaining.csv'
student_bool: True
teacher_bool: True
teacher_student_bool: True
transformer: False
active: False
pt: False # whether to pre train or not
plot_graphs: False

StudentPT:
    folder: 'text_modality_framework/Emotions_PT_210k'
    name: 'student.pt'
    dropout: 0.1
    lr: 0.0005
    batch_size: 128
    downsample: False
    epochs: 3

    hidden: [50, 128, 64, 32, 16, 32]
    input_embeding_size: 40
    hidden_size: 10
    
TeacherPT:
    folder: 'text_modality_framework/Emotion_PT_T'
    name: 'teacher.pt'
    dropout: 0.1
    lr: 0.0005
    batch_size: 128
    downsample: False
    epochs: 2
    model: 'bert-base-uncased'

    hidden: [50, 128, 64, 32, 16, 32]
    input_embeding_size: 40
    hidden_size: 10
    embed_size: 20
    
StudentTeacher:
    folder: 'text_modality_framework/0new_emotions_dp1_95'
    name: 'student_teacher.pt' 
    dropout: 0.1
    lr: 0.0005
    batch_size: 128
    epochs: 20
    model: 'bert-base-uncased'

    # pre_train_file null if no pre-training
    pre_train_file: null # filepath
    dp: True # whether or not to use differential privacy, overwrites eps
    factor: 1 # amount of public data to sample from compared to private data 
    wd: 0.0001 # weight decay
    eps: 1 # epsilon for differential privacy
    sens_ratio: 0.95 # amount of vocabulary that is defined as sensitive 

    queries: 7000
    iters: 1
    public: False # whether or not to use public data
    downsample: False # whether or not to downsample the data
    similarity: False # always null 

    hidden: [50, 128, 64, 32, 16, 32]
    input_embeding_size: 40
    hidden_size: 10
    embed_size: 20